import os
import logging
import asyncio
import io
from dotenv import load_dotenv

# –î–û–ë–ê–í–õ–ï–ù–û: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ HTTP-–∑–∞–ø—Ä–æ—Å–∞ (–≤–º–µ—Å—Ç–æ ElevenLabs SDK)
import aiohttp 

# Aiogram v3 –∏–º–ø–æ—Ä—Ç—ã
from aiogram import Bot, Dispatcher, types, F
from aiogram.fsm.storage.memory import MemoryStorage 
# –ò–ú–ü–û–†–¢ –î–õ–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –û–®–ò–ë–ö–ò –û–¢–ü–†–ê–í–ö–ò –§–ê–ô–õ–ê
from aiogram.types import FSInputFile 

# OpenAI (–ò—Å–ø–æ–ª—å–∑—É–µ–º Async –≤–µ—Ä—Å–∏—é)
from openai import AsyncOpenAI 

# --- 1. –ó–ê–ì–†–£–ó–ö–ê –ö–õ–Æ–ß–ï–ô –ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
load_dotenv()

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º ELEVENLABS_VOICE_ID, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –≤ .env
VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID") 
SYSTEM_PROMPT = os.getenv("SYSTEM_PROMPT")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API
dp = Dispatcher(storage=MemoryStorage())
bot = Bot(token=TELEGRAM_BOT_TOKEN)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


# --- 2. –õ–û–ì–ò–ö–ê –ü–ê–ú–Ø–¢–ò (–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê) ---
user_histories = {}
MAX_CONTEXT_MESSAGES = 10 

def get_history(user_id):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    if user_id not in user_histories:
        prompt_content = SYSTEM_PROMPT if SYSTEM_PROMPT else "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."
        user_histories[user_id] = [
            {"role": "system", "content": prompt_content},
        ]
    return user_histories[user_id]

def update_history(user_id, role, content):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∏ –æ–±—Ä–µ–∑–∞–µ—Ç –µ–µ –¥–æ MAX_CONTEXT_MESSAGES."""
    history = get_history(user_id)
    history.append({"role": role, "content": content})

    if len(history) > MAX_CONTEXT_MESSAGES:
        user_histories[user_id] = [history[0]] + history[-(MAX_CONTEXT_MESSAGES - 1):]


# --- 3. –§–£–ù–ö–¶–ò–ò –£–¢–ò–õ–ò–¢–´ ---
async def delete_temp_file(file_path):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —É–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏."""
    await asyncio.sleep(1)
    if os.path.exists(file_path):
        os.remove(file_path)
        logging.info(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {file_path}")


# --- 4. –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–û–û–ë–©–ï–ù–ò–ô ---

# 4.1. –°–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
@dp.message(F.text == '/start', F.chat.type == 'private')
async def handle_start(message: types.Message):
    user_id = message.from_user.id
    if user_id in user_histories:
        del user_histories[user_id]
    
    await message.reply(
        "–ü–∞–º—è—Ç—å —Å–±—Ä–æ—à–µ–Ω–∞. –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞! –ì–æ—Ç–æ–≤ –æ–±—â–∞—Ç—å—Å—è –≤ —Å—Ç–∏–ª–µ –î–æ–Ω–∏—ë—Ä–∞. üëã"
    )


# 4.2. –¢–ï–ö–°–¢ -> –¢–ï–ö–°–¢ (–° –ø–∞–º—è—Ç—å—é)
@dp.message(F.text, F.chat.type == 'private')
async def handle_text_to_text(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    user_id = message.from_user.id
    
    update_history(user_id, "user", message.text)

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=get_history(user_id)
        )
        
        reply_text = response.choices[0].message.content
        
        update_history(user_id, "assistant", reply_text)
        await message.reply(reply_text)
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {e}")
        await message.reply("–ò–∑–≤–∏–Ω–∏, –î–æ–Ω–∏—ë—Ä —Å–µ–π—á–∞—Å –∑–∞–Ω—è—Ç –∏ –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–º. –ü—Ä–æ–≤–µ—Ä—å –±–∞–ª–∞–Ω—Å OpenAI. üò•")


# 4.3. –ì–û–õ–û–° -> –ì–û–õ–û–° (–° –ø–∞–º—è—Ç—å—é –∏ —Å–∏–Ω—Ç–µ–∑–æ–º)
@dp.message(F.voice, F.chat.type == 'private')
async def handle_voice_to_voice(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action="record_voice") 
    user_id = message.from_user.id
    audio_file_path = None
    
    try:
        # 1. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (Whisper)
        voice_file_info = await bot.get_file(message.voice.file_id)
        voice_downloaded = io.BytesIO()
        await bot.download_file(voice_file_info.file_path, voice_downloaded)
        voice_downloaded.seek(0)
        
        transcript = await openai_client.audio.transcriptions.create(
            model="whisper-1", 
            file=("voice.ogg", voice_downloaded.read(), "audio/ogg"),
        )
        user_text = transcript.text
        logging.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {user_text}")

        # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (ChatGPT)
        update_history(user_id, "user", user_text)
        
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=get_history(user_id)
        )
        reply_text = response.choices[0].message.content
        update_history(user_id, "assistant", reply_text)
        
        # 3. –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ (ElevenLabs) - –ü–†–Ø–ú–û–ô AIOHTTP –ó–ê–ü–†–û–°
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}"
        headers = {
            "Accept": "audio/mpeg",
            "xi-api-key": ELEVENLABS_API_KEY,
            "Content-Type": "application/json"
        }
        data = {
            "text": reply_text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, json=data) as response:
                if response.status != 200:
                    error_message = await response.text()
                    raise Exception(f"ElevenLabs API Error (Code {response.status}): {error_message}")
                
                # 4. –ü–æ–ª—É—á–µ–Ω–∏–µ –∞—É–¥–∏–æ 
                audio_data_bytes = await response.read()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ–±–∞–π—Ç—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        audio_file_path = f"response_{message.chat.id}_{message.message_id}.mp3"
        with open(audio_file_path, "wb") as f:
            f.write(audio_data_bytes)
                
        # 4.2 –û—Ç–ø—Ä–∞–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º FSInputFile)
        telegram_file = FSInputFile(audio_file_path)
        await message.answer_voice(telegram_file)
            
        logging.info("–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–æ—Ç–≤–µ—Ç) –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π –ª–æ–≥–∏–∫–µ: {e}")
        await message.reply(f"–ò–∑–≤–∏–Ω–∏, —è –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –û—à–∏–±–∫–∞: {e}")
        
    finally:
        # 5. –û—á–∏—Å—Ç–∫–∞
        if audio_file_path and os.path.exists(audio_file_path):
            asyncio.create_task(delete_temp_file(audio_file_path))


# --- 5. –ó–ê–ü–£–°–ö –ë–û–¢–ê ---
if __name__ == '__main__':
    if not TELEGRAM_BOT_TOKEN:
        logging.error("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env.")
    else:
        logging.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
        dp.run_polling(bot, skip_updates=True)